{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d065b4a9-b1f0-45b9-a065-21d5f76d9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '112343906767590652', 'username': 'zheyuanw', 'acct': 'zheyuanw', 'display_name': '', 'locked': False, 'bot': False, 'discoverable': None, 'group': False, 'created_at': '2024-04-27T00:00:00.000Z', 'note': '', 'url': 'https://mastodon.au/@zheyuanw', 'uri': 'https://mastodon.au/users/zheyuanw', 'avatar': 'https://mastodon.au/avatars/original/missing.png', 'avatar_static': 'https://mastodon.au/avatars/original/missing.png', 'header': 'https://mastodon.au/headers/original/missing.png', 'header_static': 'https://mastodon.au/headers/original/missing.png', 'followers_count': 0, 'following_count': 0, 'statuses_count': 0, 'last_status_at': None, 'noindex': True, 'source': {'privacy': 'public', 'sensitive': False, 'language': None, 'note': '', 'fields': [], 'follow_requests_count': 0, 'hide_collections': None, 'discoverable': None, 'indexable': False}, 'emojis': [], 'roles': [], 'fields': [], 'role': {'id': '-99', 'name': '', 'permissions': '0', 'color': '', 'highlighted': False}}\n",
      "{'id': 112406064283239577, 'created_at': '2024-05-09 01:00:21 AEST', 'content': 'google bard (@deepfates) on XWatching in real time as \"slop\" becomes a term of art. the way that \"spam\"became the term for unwanted emails, \"slop\" is going in the dictionary as theterm for unwanted AI generated content  https://twitter.com/deepfates/status/1787472784106639418', 'sentiment_score': -0.4215, 'topics': ['science_&_technology'], 'url': 'https://mastodon.adamgeitgey.com/@trending/112406064128934809', 'language': 'en'}\n",
      "{'id': 112406063438224273, 'created_at': '2024-05-09 01:00:11 AEST', 'content': \"Guess who's coming for dinner?If you are lucky, it's your future lover! And if you are _not_ lucky, you willhave little time for regrets...#Germany #folktale #folklore #magic @germany @folklore  https://www.patreon.com/posts/finding-love-85821250\", 'sentiment_score': 0.8655, 'topics': ['arts_&_culture', 'diaries_&_daily_life', 'family'], 'url': 'https://thefolklore.cafe/@juergen_hubert/112406063449200001', 'language': 'en'}\n",
      "{'id': 112406064372179477, 'created_at': '2024-05-09 01:00:22 AEST', 'content': 'RFK Jr. Says Doctors Found a Dead Worm in His BrainThe presidential candidate has faced previously undisclosed health issues,including a parasite that he said ate part of his brain.  https://www.nytimes.com/2024/05/08/us/rfk-jr-brain-health-memory-loss.html', 'sentiment_score': -0.6486, 'topics': ['news_&_social_concern'], 'url': 'https://mastodon.adamgeitgey.com/@trending/112406064138734627', 'language': 'en'}\n",
      "{'id': 112406064434494121, 'created_at': '2024-05-09 01:00:18 AEST', 'content': 'Croatia ruling conservatives will form government with a far-right group afterinconclusive electionCroatiaâ€™s ruling conservatives have agreed to form a coalition with an extremeparty, which would push the country further to the right ahead of next monthâ€™sEuropean parliamentary election #presshttps://www.independent.co.uk/news/croatia-ap-zagreb-yugoslavia-b2541653.html?utm_source=press.coop', 'sentiment_score': 0.2732, 'topics': ['news_&_social_concern'], 'url': 'https://press.coop/@Independent/112406063866518352', 'language': 'en'}\n",
      "{'id': 112406064437330031, 'created_at': '2024-05-09 01:00:18 AEST', 'content': '7 civilians were killed by Russia in Odessa on April 29. Another man has diedin hospital, according to the city council. #Odessa #Russia', 'sentiment_score': -0.6705, 'topics': ['news_&_social_concern'], 'url': 'https://mastodon.social/@karakam/112406063903234656', 'language': 'en'}\n",
      "{'id': 112406063886911787, 'created_at': '2024-05-09 01:00:18 AEST', 'content': '9 of 10 wrongful death suits over deadly Astroworld crowd surge have beensettled, lawyer saysAn attorney says nine of the 10 wrongful death lawsuits filed after the 2021Astroworld festival have been settled, including one that was set to go totrial this week. #presshttps://www.seattletimes.com/entertainment/9-of-10-wrongful-death-suits-over-deadly-astroworld-crowd-surge-have-been-settled-lawyer-says/?utm_medium=Referral&utm_campaign=RSS_all&utm_source=press.coop', 'sentiment_score': -0.7351, 'topics': ['news_&_social_concern'], 'url': 'https://press.coop/@seattletimes/112406063871277996', 'language': 'en'}\n",
      "{'id': 112406064466627556, 'created_at': '2024-05-09 01:00:21 AEST', 'content': \"Super Hangman  https://store.steampowered.com/app/2910810/Super Hangman: the ultimate kids' word game! With colorful graphics andexciting challenges, it's a fun way to learn new words. Guess right, avoid thehangman, and expand your vocabulary across various topics. Let the wordadventure begin!  #Steam #Casual #FreetoPlay\", 'sentiment_score': 0.8475, 'topics': ['gaming'], 'url': 'https://mastodon.rip/@steamreleasebot/112406064101145562', 'language': 'en'}\n",
      "{'id': 112406064468107746, 'created_at': '2024-05-09 01:00:23 AEST', 'content': \"Like Hitler's Nazism, Putin's Nazism wants to expand without limits. But therewill always be a border that Russian Nazis cannot cross. It's the courage ofthose who stand against evil, the determination of those who stop destructionand save people. It's the cooperation of world countries helping to surviveand win. It's the principled action of those honoring life and not attendingthe inauguration of evil. Thanks to all who remember and help life prevail.Glory to Ukraine! #PutinNazism #Ukrai\", 'sentiment_score': 0.9622, 'topics': ['news_&_social_concern'], 'url': 'https://mastodon.social/@karakam/112406064244235996', 'language': 'en'}\n",
      "{'id': 112406064474883343, 'created_at': '2024-05-09 01:00:09 AEST', 'content': '', 'sentiment_score': 0.0, 'topics': [], 'url': 'https://mast.shitpostbot.com/@bot/112406063307937450', 'language': 'en'}\n",
      "{'id': 112406064479016937, 'created_at': '2024-05-09 01:00:15 AEST', 'content': 'In Dnipropetrovsk region, an informant of the Russian FSB who targetedmissiles at Kryvyi Rih was detained. The 27-year-old local resident tried toidentify the locations of radar stations and anti-aircraft missile systems, aswell as marked Ukrainian checkpoints and military vehicle repair bases onGoogle maps. The traitor is in custody and faces up to 12 years in prison,according to the Security Service of Ukraine. #FSB #UkraineSecurity', 'sentiment_score': -0.0772, 'topics': ['news_&_social_concern'], 'url': 'https://mastodon.social/@karakam/112406063735232143', 'language': 'en'}\n",
      "{'id': 112406064474796418, 'created_at': '2024-05-09 01:00:16 AEST', 'content': 'Happy Animal Choir  https://store.steampowered.com/app/2775230/  $2.54This is a joyful game where you can create songs using fun animal sounds andinstruments, manage and decorate the band\\'s rooms, upload sounds, create yourexclusive characters and content, and share them in the Creative Workshop.Create joy, share joy, and unleash your creativity here!\"  #Steam #Casual #Indie #Simulation', 'sentiment_score': 0.9847, 'topics': ['arts_&_culture', 'music'], 'url': 'https://mastodon.rip/@steamreleasebot/112406063754844808', 'language': 'en'}\n",
      "{'id': 112406064498167504, 'created_at': '2024-05-09 01:00:17 AEST', 'content': 'These Files Don\\'t Show Their Extensions... despite the \"Show File Extensions\"setting in Windows Explorer, apparently these SIXTEEN file types (ðŸ˜±) rely on aseparate Registry configuration. They could be set up with another handler forany other use (or abuse!) https://youtu.be/OS_v49D7w6MBig thanks to @SnykSec for sponsoring this video! Try Snyk for free and findvulnerabilities in your code and applications! https://jh.live/snyk', 'sentiment_score': 0.795, 'topics': ['science_&_technology'], 'url': 'https://infosec.exchange/@JohnHammond/112406063862452138', 'language': 'en'}\n",
      "{'id': 112406064507494425, 'created_at': '2024-05-09 01:00:16 AEST', 'content': 'WHITE HOLE WEDNESDAYSeries XII - SkipperLink:https://smegadrive.ganymede.tv/memelab/1868164/SSBhcmUgaGVyZSB0byBjaGFsbGVuZ2UgdGhleXMgd2hvIGtpbGxzIG15IGJyb3RoZXI/26#RedDwarf #SmegaDrive #RandomPockets', 'sentiment_score': 0.0, 'topics': ['sports'], 'url': 'https://mastodon.social/@RedDwarfShuffle/112406063774250774', 'language': 'en'}\n",
      "{'id': 112406063879314794, 'created_at': '2024-05-09 01:00:18 AEST', 'content': 'BetterHelp customers begin receiving refund notices from $7.8M data privacysettlement, FTC saysMany current and former BetterHelp customers have begun receiving refundeligibility notices spanning from a $7.8 million settlement reached with theonline therapy provider last year over... #presshttps://www.seattletimes.com/business/betterhelp-customers-begin-receiving-refund-notices-from-7-8m-data-privacy-settlement-ftc-says/?utm_medium=Referral&utm_campaign=RSS_all&utm_source=press.coop', 'sentiment_score': 0.1027, 'topics': ['business_&_entrepreneurs', 'news_&_social_concern'], 'url': 'https://press.coop/@seattletimes/112406063881488726', 'language': 'en'}\n",
      "{'id': 112406064605412195, 'created_at': '2024-05-09 01:00:20 AEST', 'content': \"'Nobody expected this' - Dortmund target Wembley winDespite a disappointing domestic campaign, Borussia Dortmund are one game awayfrom becoming European champions for the second time. #presshttps://www.bbc.com/sport/articles/cl5kpq4e32go?utm_source=press.coop\", 'sentiment_score': 0.0516, 'topics': ['sports'], 'url': 'https://press.coop/@BBCSport/112406064027003007', 'language': 'en'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m listener \u001b[38;5;241m=\u001b[39m Listener(\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_public\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlistener\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StopStreamingException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mastodon\\utility.py:49\u001b[0m, in \u001b[0;36mapi_version.<locals>.api_min_version_decorator.<locals>.wrapper\u001b[1;34m(function, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m major \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmastodon_major \u001b[38;5;129;01mand\u001b[39;00m minor \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmastodon_minor \u001b[38;5;129;01mand\u001b[39;00m patch \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmastodon_patch:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MastodonVersionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion check failed (Need version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, patch is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmastodon_patch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mastodon\\streaming_endpoints.py:38\u001b[0m, in \u001b[0;36mMastodon.stream_public\u001b[1;34m(self, listener, run_async, timeout, reconnect_async, reconnect_async_wait_sec, local, remote)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MastodonIllegalArgumentError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass both local and remote - use either one or the other.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m     base \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/remote\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_async\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconnect_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreconnect_async\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconnect_async_wait_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreconnect_async_wait_sec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mastodon\\internals.py:540\u001b[0m, in \u001b[0;36mMastodon.__stream\u001b[1;34m(self, endpoint, listener, params, run_async, timeout, reconnect_async, reconnect_async_wait_sec)\u001b[0m\n\u001b[0;32m    538\u001b[0m connection \u001b[38;5;241m=\u001b[39m connect_func()\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m closing(connection) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[1;32m--> 540\u001b[0m     \u001b[43mlistener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mastodon\\streaming.py:125\u001b[0m, in \u001b[0;36mStreamListener.handle_stream\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    120\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m    121\u001b[0m         exception,\n\u001b[0;32m    122\u001b[0m         err\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     event \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mastodon\\streaming.py:224\u001b[0m, in \u001b[0;36mStreamListener._dispatch\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    222\u001b[0m         handler()\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m         \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     handler(name, payload)\n",
      "Cell \u001b[1;32mIn[12], line 67\u001b[0m, in \u001b[0;36mListener.on_update\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, status):\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         toot_processed \u001b[38;5;241m=\u001b[39m \u001b[43mtoot_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28mprint\u001b[39m(toot_processed)\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m, in \u001b[0;36mtoot_processing\u001b[1;34m(raw_toot)\u001b[0m\n\u001b[0;32m     41\u001b[0m sentiment_score \u001b[38;5;241m=\u001b[39m sid\u001b[38;5;241m.\u001b[39mpolarity_scores(content)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     43\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokenizer(content, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 44\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m scores \u001b[38;5;241m=\u001b[39m expit(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     46\u001b[0m topics \u001b[38;5;241m=\u001b[39m [class_mapping[i] \u001b[38;5;28;01mfor\u001b[39;00m i, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m((scores \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m prediction]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1191\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1191\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1202\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1203\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:828\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    819\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    821\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    822\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    823\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    827\u001b[0m )\n\u001b[1;32m--> 828\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    841\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:517\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    506\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    507\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    508\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m         output_attentions,\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 517\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:448\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    445\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    446\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 448\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:461\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    460\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 461\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:372\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 372\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    374\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from mastodon import Mastodon, StreamListener\n",
    "import html2text\n",
    "import pytz\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from scipy.special import expit\n",
    "\n",
    "# Mastodon Access Token and Base URL\n",
    "MASTODON_ACCESS_TOKEN = \"Q8oYzpl2vDz6-SOcyf2upfwpUiKS-K9N4qTVLyo2qfA\"\n",
    "MASTODON_BASE_URL = 'https://mastodon.au'\n",
    "\n",
    "# Initialize Mastodon API\n",
    "m = Mastodon(api_base_url=MASTODON_BASE_URL, access_token=MASTODON_ACCESS_TOKEN)\n",
    "\n",
    "# Sentiment Analysis and Text-to-Plain Converter\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "html_converter = html2text.HTML2Text()\n",
    "html_converter.ignore_links = True\n",
    "\n",
    "# Load Topic Classification Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"cardiffnlp/tweet-topic-21-multi\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "class_mapping = model.config.id2label\n",
    "\n",
    "\n",
    "# Function for Processing Toots\n",
    "def toot_processing(raw_toot):\n",
    "    # Convert and Reformat DateTime to Australia/Sydney Timezone\n",
    "    sydney_timezone = pytz.timezone('Australia/Sydney')\n",
    "    sydney_datetime = raw_toot['created_at'].astimezone(sydney_timezone)\n",
    "    created_at = sydney_datetime.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "    # Extract Text Content and Analyze Sentiment\n",
    "    content = html_converter.handle(raw_toot['content']).replace(\"\\n\", \"\")\n",
    "    sentiment_score = sid.polarity_scores(content)[\"compound\"]\n",
    "\n",
    "    tokens = tokenizer(content, return_tensors='pt', max_length=512, truncation=True).to(device)\n",
    "    output = model(**tokens)\n",
    "    scores = expit(output[\"logits\"][0].detach().cpu().numpy())\n",
    "    topics = [class_mapping[i] for i, prediction in enumerate((scores >= 0.5) * 1) if prediction]\n",
    "\n",
    "    return {\n",
    "        'id': raw_toot['id'],\n",
    "        'created_at': created_at,\n",
    "        'content': content,\n",
    "        'sentiment_score': sentiment_score,\n",
    "        \"topics\": topics,\n",
    "        'url': raw_toot['url'],\n",
    "        'language': raw_toot['language']\n",
    "    }\n",
    "\n",
    "# Listener Class for Streaming Toots\n",
    "class Listener(StreamListener):\n",
    "    def __init__(self, upper_limit):\n",
    "        super().__init__()\n",
    "        self.count = 0\n",
    "        self.upper_limit = upper_limit\n",
    "\n",
    "    def on_update(self, status):\n",
    "        if status[\"language\"] == \"en\":\n",
    "            toot_processed = toot_processing(status)\n",
    "            print(toot_processed)\n",
    "            self.count += 1\n",
    "            if self.count % 50 == 0:\n",
    "                print(f\"Has harvested {self.count} toots.\")\n",
    "            if self.count >= self.upper_limit:\n",
    "                raise StopStreamingException(\"Stopping streaming.\")\n",
    "\n",
    "\n",
    "# Custom Exception to Stop Streaming\n",
    "class StopStreamingException(Exception):\n",
    "    pass\n",
    "    \n",
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    header = {\"Authorization\": f\"Bearer {MASTODON_ACCESS_TOKEN}\"}\n",
    "    r = requests.get(f\"{MASTODON_BASE_URL}/api/v1/accounts/verify_credentials\", headers=header)\n",
    "    print(r.json())\n",
    "    listener = Listener(10000)\n",
    "    try:\n",
    "        m.stream_public(listener)\n",
    "    except StopStreamingException as e:\n",
    "        print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3c1b09-c39e-4a95-95c9-539debb57313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphington\n",
      "[-37.7784081, 145.0306]\n",
      "Altona North\n",
      "[-37.8441238, 144.861618]\n",
      "Ararat\n",
      "[-37.2828064, 142.935608]\n",
      "Bacchus Marsh\n",
      "[-37.674633, 144.4354]\n",
      "Bairnsdale\n",
      "[-37.829895, 147.620209]\n",
      "Ballarat\n",
      "[-37.5293274, 143.842438]\n",
      "Beechworth\n",
      "[-36.37299, 146.679077]\n",
      "Benalla\n",
      "[-36.54932, 145.997223]\n",
      "Bendigo\n",
      "[-36.77841, 144.300064]\n",
      "Boolarra\n",
      "[-38.36981, 146.2751]\n",
      "Boolarra South\n",
      "[-38.44398, 146.2742]\n",
      "Box Hill\n",
      "[-37.8287277, 145.1324]\n",
      "Bright\n",
      "[-36.73228, 146.9702]\n",
      "Brighton\n",
      "[-37.9135475, 144.998]\n",
      "Broadford\n",
      "[-37.2078857, 145.04805]\n",
      "Brooklyn\n",
      "[-37.8220978, 144.8471]\n",
      "Callignee\n",
      "[-38.36169, 146.588211]\n",
      "Camperdown\n",
      "[-38.2248344, 143.140152]\n",
      "Castlemaine\n",
      "[-37.0730247, 144.233292]\n",
      "Churchill\n",
      "[-38.3043137, 146.414932]\n",
      "Cobden\n",
      "[-38.32716, 143.076]\n",
      "Colac\n",
      "[-38.3456841, 143.594269]\n",
      "Dandenong\n",
      "[-37.98576, 145.1987]\n",
      "Daylesford\n",
      "[-37.3410339, 144.130463]\n",
      "Drysdale\n",
      "[-38.1913528, 144.550659]\n",
      "Echuca\n",
      "[-36.12591, 144.754288]\n",
      "Flynn\n",
      "[-38.17107, 146.6933]\n",
      "Flynns Creek\n",
      "[-38.24396, 146.6362]\n",
      "Footscray\n",
      "[-37.80266, 144.8778]\n",
      "Geelong South\n",
      "[-38.17356, 144.3703]\n",
      "Gisborne\n",
      "[-37.4853172, 144.5862]\n",
      "Glengarry\n",
      "[-38.12751, 146.5691]\n",
      "Hamilton\n",
      "[-37.73387, 142.020813]\n",
      "Healesville\n",
      "[-37.6468239, 145.5275]\n",
      "Heathcote\n",
      "[-36.92107, 144.709946]\n",
      "Hernes Oak\n",
      "[-38.1853447, 146.323441]\n",
      "Heywood\n",
      "[-38.1323051, 141.631821]\n",
      "Horsham\n",
      "[-36.72263, 142.175415]\n",
      "Kerang\n",
      "[-35.7475281, 143.924866]\n",
      "Kinglake\n",
      "[-37.5337448, 145.340515]\n",
      "Kingsville\n",
      "[-37.81191, 144.8741]\n",
      "Kyneton\n",
      "[-37.24706, 144.451111]\n",
      "Lakes Entrance\n",
      "[-37.8716469, 148.006744]\n",
      "Lancefield\n",
      "[-37.2782669, 144.73526]\n",
      "Leongatha\n",
      "[-38.4689522, 145.956421]\n",
      "Lorne\n",
      "[-38.5403671, 143.9738]\n",
      "Macedon\n",
      "[-37.4230652, 144.562225]\n",
      "Macleod\n",
      "[-37.722477, 145.0576]\n",
      "Maffra\n",
      "[-37.9596977, 146.991745]\n",
      "Mallacoota\n",
      "[-37.56016, 149.751114]\n",
      "Mansfield\n",
      "[-37.0508, 146.077087]\n",
      "Melbourne CBD\n",
      "[-37.8073959, 144.97]\n",
      "Melton\n",
      "[-37.7064552, 144.5669]\n",
      "Mildura\n",
      "[-34.1635132, 142.139374]\n",
      "Mildura\n",
      "[-34.19561, 142.1616]\n",
      "Moe\n",
      "[-38.1864662, 146.258331]\n",
      "Mooroolbark\n",
      "[-37.77512, 145.3284]\n",
      "Morwell East\n",
      "[-38.229393, 146.424454]\n",
      "Morwell South\n",
      "[-38.2392921, 146.3873]\n",
      "Myrtleford\n",
      "[-36.5539742, 146.72081]\n",
      "Orbost\n",
      "[-37.7059746, 148.456284]\n",
      "Ouyen\n",
      "[-35.0655365, 142.318649]\n",
      "Point Cook\n",
      "[-37.9263153, 144.7567]\n",
      "Porepunkah\n",
      "[-36.70419, 146.9169]\n",
      "Portland\n",
      "[-38.3525276, 141.6071]\n",
      "Rosedale\n",
      "[-38.15588, 146.7842]\n",
      "Rosedale\n",
      "[-38.15044, 146.7858]\n",
      "Rutherglen\n",
      "[-36.0538254, 146.463989]\n",
      "Sale\n",
      "[-38.102684, 147.057541]\n",
      "Shepparton\n",
      "[-36.3808365, 145.406616]\n",
      "Spotswood\n",
      "[-37.82743, 144.8801]\n",
      "Sunbury\n",
      "[-37.58954, 144.719727]\n",
      "Swan Hill\n",
      "[-35.34331, 143.5341]\n",
      "Swan Hill\n",
      "[-35.34314, 143.534088]\n",
      "Torquay\n",
      "[-38.3079338, 144.310516]\n",
      "Traralgon\n",
      "[-38.1942825, 146.531464]\n",
      "Traralgon East\n",
      "[-38.19631, 146.5621]\n",
      "Traralgon South\n",
      "[-38.29585, 146.5392]\n",
      "Tyers\n",
      "[-38.1300278, 146.482513]\n",
      "Tyers North\n",
      "[-38.12967, 146.4828]\n",
      "Wallan\n",
      "[-37.41652, 144.981232]\n",
      "Wangaratta\n",
      "[-36.36926, 146.3133]\n",
      "Warburton\n",
      "[-37.75449, 145.688278]\n",
      "Warragul\n",
      "[-38.1666527, 145.941544]\n",
      "Warrnambool\n",
      "[-38.3860931, 142.510986]\n",
      "Willow Grove\n",
      "[-38.07072, 146.1779]\n",
      "Wodonga\n",
      "[-36.1377754, 146.8983]\n",
      "Wonthaggi\n",
      "[-38.5871048, 145.578491]\n",
      "Yallourn North\n",
      "[-38.16144, 146.3629]\n",
      "Yarra Glen\n",
      "[-37.65686, 145.373459]\n",
      "Yarrawonga\n",
      "[-36.01634, 146.013016]\n",
      "Yinnar\n",
      "[-38.32779, 146.3371]\n",
      "Yinnar\n",
      "[-38.32676, 146.3261]\n"
     ]
    }
   ],
   "source": [
    "import requests,json\n",
    "url=\"https://gateway.api.epa.vic.gov.au/environmentMonitoring/v1/sites\"\n",
    "params={\"environmentalSegment\":\"air\"}\n",
    "headers={\n",
    "    'User-agent':'curl/8.4.0',\n",
    "    'Cache-Control':'no-cache',\n",
    "    'X-API-Key':'f6694fb4cb45496a816c8b630e885f92',\n",
    "}\n",
    "response=requests.get(url,params=params,headers=headers)\n",
    "data=json.loads(response.text)\n",
    "\n",
    "for record in sorted(data['records'], key=lambda x: x['siteName']):\n",
    "    print(record['siteName'])\n",
    "    print(record['geometry']['coordinates'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1483807-b88f-4709-9e06-d336d2035fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ijson in c:\\users\\zheyu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1591a83-ecd8-40e1-81cf-718effb20076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a68414-71a0-481e-badc-0003a26cf9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
